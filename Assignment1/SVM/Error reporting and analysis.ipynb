{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # for handling multi-dimensional array operation\n",
    "import pandas as pd  # for reading data from csv \n",
    "import statsmodels.api as sm  # for finding the p-value\n",
    "from sklearn.preprocessing import MinMaxScaler  # for normalization\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = '/home/tushar/Downloads/SVM_accuracy_final_new_'#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col = 'pred'\n",
    "actual_col = 'actual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame()\n",
    "for division in [1,2,3,4,5]:\n",
    "    accuracy_df = accuracy_df.append(pd.read_pickle(parent_path+str(division)+'.pkl'))\n",
    "accuracy_df = accuracy_df.rename(columns={'predicted_lable':'pred','true_label':'actual','words':'word','pred_tag':'pred','actual_tag':'actual'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7170435594575225\n"
     ]
    }
   ],
   "source": [
    "print(len(accuracy_df[accuracy_df[pred_col]==accuracy_df[actual_col]])/len(accuracy_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = accuracy_df[actual_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PRT', '.', 'ADV', 'ADJ', 'ADP', 'DET', 'NOUN', 'VERB', 'PRON',\n",
       "       'CONJ', 'NUM', 'X'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRT 29828 0.09075365428456483\n",
      ". 147530 0.999972886870467\n",
      "ADV 56232 0.042164603784322095\n",
      "ADJ 83695 0.024314475177728657\n",
      "ADP 144725 0.842881326653999\n",
      "DET 136975 0.9629202409198759\n",
      "NOUN 275475 0.9572883201742445\n",
      "VERB 182712 0.46877052410350717\n",
      "PRON 49326 0.8783805700847424\n",
      "CONJ 38139 0.8025380843755736\n",
      "NUM 14873 0.04020708666711491\n",
      "X 1386 0.0\n"
     ]
    }
   ],
   "source": [
    "per_pos_df = pd.DataFrame()\n",
    "for tag in unique_tags:\n",
    "    temp_accuracy_df = accuracy_df[accuracy_df[actual_col]==tag]\n",
    "    accuracy = len(temp_accuracy_df[temp_accuracy_df[pred_col]==temp_accuracy_df[actual_col]])/len(temp_accuracy_df)\n",
    "    print(tag,len(temp_accuracy_df),accuracy)\n",
    "    row = {}\n",
    "    row['tag'] = tag\n",
    "    row['count'] = len(temp_accuracy_df)\n",
    "    row['accuracy'] = accuracy\n",
    "    per_pos_df = per_pos_df.append(row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = accuracy_df.groupby([pred_col,actual_col])['word'].count().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrl}\n",
      "\\toprule\n",
      "{} &  accuracy &     count &   tag \\\\\n",
      "\\midrule\n",
      "0  &      0.09 &   29828.0 &   PRT \\\\\n",
      "1  &      1.00 &  147530.0 &     . \\\\\n",
      "2  &      0.04 &   56232.0 &   ADV \\\\\n",
      "3  &      0.02 &   83695.0 &   ADJ \\\\\n",
      "4  &      0.84 &  144725.0 &   ADP \\\\\n",
      "5  &      0.96 &  136975.0 &   DET \\\\\n",
      "6  &      0.96 &  275475.0 &  NOUN \\\\\n",
      "7  &      0.47 &  182712.0 &  VERB \\\\\n",
      "8  &      0.88 &   49326.0 &  PRON \\\\\n",
      "9  &      0.80 &   38139.0 &  CONJ \\\\\n",
      "10 &      0.04 &   14873.0 &   NUM \\\\\n",
      "11 &      0.00 &    1386.0 &     X \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(per_pos_df.round(2).to_latex())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tushar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "prec_recall = pd.DataFrame()\n",
    "for idx in confusion_matrix.index:\n",
    "    row = {}\n",
    "    row['tag'] = idx\n",
    "    row['recall'] = rec = recall(i,np.array(confusion_matrix).T)\n",
    "    row['precision'] = prec = precision(i,np.array(confusion_matrix).T)\n",
    "    row['F1 score'] = 2*(rec * prec) / (rec + prec)\n",
    "\n",
    "\n",
    "    i+=1\n",
    "    prec_recall = prec_recall.append(row,ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "actual &  . &    ADJ &     ADP &    ADV &   CONJ &     DET &    NOUN &   NUM &   PRON &    PRT &   VERB &     X \\\\\n",
      "pred &    &        &         &        &        &         &         &       &        &        &        &       \\\\\n",
      "\\midrule\n",
      "ADJ  &  0 &   2035 &       0 &   1755 &      0 &       0 &     340 &   303 &      0 &    105 &    330 &     0 \\\\\n",
      "ADP  &  0 &   2284 &  121986 &   5401 &   3489 &     494 &     383 &     0 &    224 &  15119 &   1031 &    20 \\\\\n",
      "ADV  &  0 &    720 &     368 &   2371 &      0 &       0 &      25 &     0 &      0 &      0 &      0 &     0 \\\\\n",
      "CONJ &  0 &      0 &     525 &     11 &  30608 &       0 &       0 &     0 &      0 &      0 &      0 &     4 \\\\\n",
      "DET  &  0 &   1862 &    5679 &   1161 &     12 &  131896 &     402 &  1750 &   2864 &    745 &     65 &    20 \\\\\n",
      "NOUN &  4 &  73898 &    7957 &  27875 &    449 &    2399 &  263709 &  9341 &   2008 &   3485 &  92930 &  1212 \\\\\n",
      "NUM  &  0 &      0 &       0 &      0 &      0 &       0 &       0 &   598 &      0 &      0 &      0 &     0 \\\\\n",
      "PRON &  0 &     56 &    1080 &   6024 &      0 &     577 &     563 &   859 &  43327 &   3865 &      5 &     6 \\\\\n",
      "PRT  &  0 &      0 &    1914 &      0 &      0 &       0 &       0 &     0 &      0 &   2707 &      0 &     1 \\\\\n",
      "VERB &  0 &   2703 &    1825 &   8070 &   2461 &     478 &    5818 &     0 &    877 &    875 &  85650 &    11 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix.astype(int).to_latex(index=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "{} &  F1 score &  precision &  recall &   tag \\\\\n",
      "\\midrule\n",
      "0 &       NaN &       0.00 &    0.00 &   ADJ \\\\\n",
      "1 &      0.02 &       0.02 &    0.03 &   ADP \\\\\n",
      "2 &      0.01 &       0.11 &    0.00 &   ADV \\\\\n",
      "3 &      0.00 &       0.00 &    0.00 &  CONJ \\\\\n",
      "4 &      0.00 &       0.00 &    0.00 &   DET \\\\\n",
      "5 &      0.01 &       0.00 &    0.02 &  NOUN \\\\\n",
      "6 &       NaN &       0.00 &    0.00 &   NUM \\\\\n",
      "7 &      0.02 &       0.02 &    0.07 &  PRON \\\\\n",
      "8 &       NaN &       0.00 &    0.00 &   PRT \\\\\n",
      "9 &      0.01 &       0.01 &    0.03 &  VERB \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prec_recall.round(2).to_latex(index=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1 score     0.010063\n",
       "precision    0.014947\n",
       "recall       0.014750\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
