{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/manojbhadu/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/manojbhadu/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/manojbhadu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/manojbhadu/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('punkt')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import brown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_corpus = list(nltk.corpus.brown.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(brown_corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown_corpus)  #total no. of sentences in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data =train_test_split(brown_corpus,test_size=0.20,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45872 11468\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'DET')\n",
      "('Fulton', 'NOUN')\n",
      "('County', 'NOUN')\n",
      "('Grand', 'ADJ')\n",
      "('Jury', 'NOUN')\n",
      "('said', 'VERB')\n",
      "('Friday', 'NOUN')\n",
      "('an', 'DET')\n",
      "('investigation', 'NOUN')\n",
      "('of', 'ADP')\n",
      "(\"Atlanta's\", 'NOUN')\n",
      "('recent', 'ADJ')\n",
      "('primary', 'NOUN')\n",
      "('election', 'NOUN')\n",
      "('produced', 'VERB')\n",
      "('``', '.')\n",
      "('no', 'DET')\n",
      "('evidence', 'NOUN')\n",
      "(\"''\", '.')\n",
      "('that', 'ADP')\n",
      "('any', 'DET')\n",
      "('irregularities', 'NOUN')\n",
      "('took', 'VERB')\n",
      "('place', 'NOUN')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "#print word with its tag for 1st sentence\n",
    "for sent in brown_corpus[:1]:\n",
    "    for tupl in sent:\n",
    "        print(tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranforming dataset into each word and his tag\n",
    "train_tagged_words = [ tupl for sent in train_data for tupl in sent ]\n",
    "test_tagged_words = [ tupl for sent in test_data for tupl in sent ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DET'), ('will', 'VERB'), ('mean', 'VERB')]\n",
      "[('Muscle', 'NOUN'), ('weakness', 'NOUN'), ('did', 'VERB')]\n",
      "933117\n",
      "228075\n"
     ]
    }
   ],
   "source": [
    "print(train_tagged_words[:3])\n",
    "print(test_tagged_words[:3])\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "50749\n",
      "{'ADV', 'VERB', 'DET', 'PRT', 'PRON', 'ADP', 'ADJ', 'NOUN', 'X', 'CONJ', 'NUM', '.'}\n"
     ]
    }
   ],
   "source": [
    "#printing tags and words(vocab size) in our data\n",
    "\n",
    "tags = {tag for words,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))\n",
    "\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = list(all_tags)\n",
    "tpm_dict = {}\n",
    "for tag in unique_tags:\n",
    "    for suc_tag in unique_tags:\n",
    "        tpm_dict[tag][suc_tag] = 0\n",
    "for sent in training_sents:\n",
    "    for pos in range(len(sent)-1):\n",
    "        tpm_dict[sent[pos][1]][sent[pos+1][1]]+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission and Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_prob(word,tag,datset,alpha=0.2):               #add alpha smoothing\n",
    "    tag_count=0             #no. of times given tag appear in datset\n",
    "    for i in range(len(datset)):\n",
    "        if datset[i][1] == tag:\n",
    "            tag_count+=1\n",
    "    word_with_tag=0          #no. of times given word tagged as given tag\n",
    "    for i in range(len(datset)):\n",
    "        if datset[i][1] == tag and datset[i][0] == word :\n",
    "            word_with_tag+=1\n",
    "    \n",
    "    vocab = {word for word,tag in train_tagged_words}\n",
    "    V = len(vocab)\n",
    "    prob = (word_with_tag+alpha)/(tag_count+(alpha*V))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01105080230279275"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = emission_prob('will','VERB',train_tagged_words)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_prob(tag1, tag2, dataset):             #calculating tag2 given tag1\n",
    "    all_tags = [word_tag[1] for word_tag in dataset]\n",
    "    count_tag1 = len([tag for tag in all_tags if tag==tag1])\n",
    "    tag2_with_tag1 = 0\n",
    "    for i in range(len(all_tags)-1):\n",
    "        if tag1 == all_tags[i] and tag2 == all_tags[i+1]:\n",
    "            tag2_with_tag1+=1\n",
    "    \n",
    "    prob = (tag2_with_tag1)/(count_tag1)\n",
    "    return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n",
      "ADP\n",
      "ADP given VERB is 0.16916213616736814\n"
     ]
    }
   ],
   "source": [
    "t1 = train_tagged_words[1][1]\n",
    "print(t1)\n",
    "t2 = train_tagged_words[3][1]\n",
    "print(t2)\n",
    "tp = transition_prob(t1,t2,train_tagged_words)\n",
    "print(t2,\"given\",t1,'is',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table for transtion probability\n",
    "#(i,j) element of table represent the transtion from i to j\n",
    "all_tags = {word_tag[1] for word_tag in train_tagged_words}\n",
    "all_tags = list(all_tags)\n",
    "n=len(all_tags)\n",
    "transition_matrix = np.zeros((n,n), dtype = float)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        transition_matrix[i,j] = transition_prob(all_tags[i],all_tags[j],train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_transition = pd.DataFrame(transition_matrix, columns = all_tags, index=all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRT</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>X</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.095735</td>\n",
       "      <td>0.239483</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.048522</td>\n",
       "      <td>0.143969</td>\n",
       "      <td>0.136873</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.170426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.184265</td>\n",
       "      <td>0.162771</td>\n",
       "      <td>0.065287</td>\n",
       "      <td>0.055028</td>\n",
       "      <td>0.169162</td>\n",
       "      <td>0.057545</td>\n",
       "      <td>0.097818</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.080778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.064863</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.239990</td>\n",
       "      <td>0.626158</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.012925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.622861</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>0.090280</td>\n",
       "      <td>0.019540</td>\n",
       "      <td>0.035894</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.012202</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.077491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.054189</td>\n",
       "      <td>0.705815</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.011646</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.103754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.041217</td>\n",
       "      <td>0.454722</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>0.070403</td>\n",
       "      <td>0.020222</td>\n",
       "      <td>0.082304</td>\n",
       "      <td>0.258943</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.009926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.087847</td>\n",
       "      <td>0.057149</td>\n",
       "      <td>0.655236</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.037010</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.099238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.026672</td>\n",
       "      <td>0.158508</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.244749</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>0.149988</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.284281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.008515</td>\n",
       "      <td>0.051088</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>0.052034</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.494797</td>\n",
       "      <td>0.026490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.090341</td>\n",
       "      <td>0.193969</td>\n",
       "      <td>0.151436</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.066632</td>\n",
       "      <td>0.073732</td>\n",
       "      <td>0.112160</td>\n",
       "      <td>0.246629</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>0.020875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.020923</td>\n",
       "      <td>0.046047</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>0.131586</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>0.381481</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.038736</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.271154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.077875</td>\n",
       "      <td>0.094205</td>\n",
       "      <td>0.149886</td>\n",
       "      <td>0.031952</td>\n",
       "      <td>0.106550</td>\n",
       "      <td>0.112499</td>\n",
       "      <td>0.042005</td>\n",
       "      <td>0.136648</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.087768</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.140727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADV      VERB       DET       PRT      PRON       ADP       ADJ  \\\n",
       "ADV   0.095735  0.239483  0.073005  0.028674  0.048522  0.143969  0.136873   \n",
       "VERB  0.103937  0.184265  0.162771  0.065287  0.055028  0.169162  0.057545   \n",
       "DET   0.017361  0.064863  0.005990  0.001945  0.009926  0.009008  0.239990   \n",
       "PRT   0.035475  0.622861  0.082523  0.011699  0.007170  0.090280  0.019540   \n",
       "PRON  0.054189  0.705815  0.017431  0.023014  0.008109  0.056109  0.009726   \n",
       "ADP   0.015533  0.041217  0.454722  0.014117  0.070403  0.020222  0.082304   \n",
       "ADJ   0.009475  0.017168  0.005926  0.019619  0.003728  0.087847  0.057149   \n",
       "NOUN  0.026672  0.158508  0.016115  0.017945  0.020212  0.244749  0.013095   \n",
       "X     0.008515  0.051088  0.005676  0.008515  0.008515  0.052034  0.003784   \n",
       "CONJ  0.090341  0.193969  0.151436  0.024816  0.066632  0.073732  0.112160   \n",
       "NUM   0.020923  0.046047  0.014369  0.005966  0.009327  0.131586  0.058819   \n",
       ".     0.077875  0.094205  0.149886  0.031952  0.106550  0.112499  0.042005   \n",
       "\n",
       "          NOUN         X      CONJ       NUM         .  \n",
       "ADV   0.032400  0.000089  0.017497  0.013328  0.170426  \n",
       "VERB  0.097818  0.000157  0.014318  0.008936  0.080778  \n",
       "DET   0.626158  0.001436  0.000645  0.009753  0.012925  \n",
       "PRT   0.035894  0.000084  0.012202  0.004780  0.077491  \n",
       "PRON  0.009095  0.000025  0.011646  0.001086  0.103754  \n",
       "ADP   0.258943  0.000498  0.001915  0.030200  0.009926  \n",
       "ADJ   0.655236  0.000520  0.037010  0.007084  0.099238  \n",
       "NOUN  0.149988  0.000329  0.060259  0.007848  0.284281  \n",
       "X     0.056764  0.494797  0.026490  0.000000  0.283822  \n",
       "CONJ  0.246629  0.000586  0.000228  0.018596  0.020875  \n",
       "NUM   0.381481  0.000168  0.038736  0.021427  0.271154  \n",
       ".     0.136648  0.001348  0.087768  0.018529  0.140727  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table for emission probability\n",
    "#(i,j) element of table is emission probability of word vocab[j] in state i\n",
    "# vocab = list({word_tag[0] for word_tag in train_tagged_words})\n",
    "# all_tags = list({word_tag[1] for word_tag in train_tagged_words})\n",
    "# V = len(vocab)\n",
    "# n = len(all_tags)\n",
    "# emission_matrix = np.zeros((n,V))\n",
    "# for i in range(n):\n",
    "#     for j in range(V):\n",
    "#         emission_matrix[i,j] = emission_prob(vocab[j],all_tags[i],train_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Algoritham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence, training_data):\n",
    "    states = []\n",
    "    all_tags = list({word_tag[1] for word_tag in training_data})\n",
    "    T = len(sentence)\n",
    "    for i in range(T):\n",
    "        p=[]\n",
    "        for tag in all_tags:\n",
    "            #compute transition probabilities\n",
    "            if i == 0:\n",
    "                trans_prob = pd_transition.loc['.',tag]\n",
    "            else:\n",
    "                trans_prob = pd_transition.loc[states[-1],tag]\n",
    "            #compute emission probabilities\n",
    "            emis_prob = emission_prob(sentence[i],tag,train_tagged_words)\n",
    "            #state probability P(Sk->Sk+1)*P(Ok|Sk) , trans_prob*emis_prob\n",
    "            state_probability = trans_prob*emis_prob\n",
    "            p.append(state_probability)\n",
    "        \n",
    "        max_state_prob = max(p)                               #max probability\n",
    "        argmax_state_prob = all_tags[p.index(max_state_prob)]      #state with max probabiltiy\n",
    "\n",
    "        states.append(argmax_state_prob)\n",
    "    return list(zip(sentence,states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [i[0] for i in test_data[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = viterbi(test, train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRON'),\n",
       " ('replaced', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('flashlight', 'NOUN'),\n",
       " ('where', 'ADV'),\n",
       " ('it', 'PRON'),\n",
       " ('had', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('stowed', 'PRT'),\n",
       " (',', '.'),\n",
       " ('got', 'VERB'),\n",
       " ('into', 'ADP'),\n",
       " ('his', 'DET'),\n",
       " ('own', 'ADJ'),\n",
       " ('car', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('backed', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('out', 'PRT'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('garage', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Accuracy calculation , but takes long time\n",
    "\n",
    "#rndom = [random.randint(1,len(test_data)) for x in range(10)]\n",
    "#test_run = [test_data[i] for i in rndom]\n",
    "# test_run = test_data[5]\n",
    "# test_run_base = [tup for sent in test_run for tup in sent]\n",
    "# test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "\n",
    "# start = time.time()\n",
    "# tagged_seq = viterbi(test_tagged_words,train_tagged_words)\n",
    "# end = time.time()\n",
    "# difference = end-start\n",
    "\n",
    "# print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# # accuracy\n",
    "# check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "# accuracy = len(check)/len(tagged_seq)\n",
    "# print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [i[0] for i in test_data[5]]\n",
    "pred_tags=viterbi(test,train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 6, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 4]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tag = [i[1] for i in pred_tags]\n",
    "real_tag = [i[1] for i in test_data[5]]\n",
    "confusion_matrix(real_tag,pred_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " '.',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " '.',\n",
       " 'VERB',\n",
       " 'ADV',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'ADV',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'NUM',\n",
       " '.']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
